## 工作交接

### 搜狐内容接口

#### 主要内容

1. 扫描全量数据，将未扫描到的sohu_album和sohu_video设置为下线状态
2. 更新搜狐自制内容
3. 对于返回状态位status不为200的video数据，存放在sohu_download_info表中，针对这些数据有job会自动进行扫描，同时后台服务支持重试
4. 生成的文件目录在服务器 **139.196.189.182**，文件目录为**/prepared/xml**
5. 项目部署在服务器 **139.196.189.182  /app/tomcat07** 

#### 遇到的问题

1. 搜狐接口中新增字段

   ​	对应的sohu_album或者sohu_video表添加字段

2. 服务器中的/prepared/xml文件目录过多

   ​	清楚之前的下载文件

### BI系统

#### 主要内容

1. 目前BI系统部署在**47.100.91.36**服务器上，jar包在 **/Springboot_jars/BI_JAR**
2. 前端项目上传到 **http://139.196.37.202:9000/BI/BIWeb** 
3. 后端项目上传到 **http://139.196.37.202:9000/BI/nebula_bi** 
4. 对应的数据库 表 **139.196.188.223	nebula**

####  遇到的问题

1. 新增驻地

   1. Home.vue新增对应的option
   2. ![avatar](http://static.jiebianjia.com/typora/f7cf99b49e0695b49b4fd0a63600b742.png)
   3. Login.vue过滤相关的产品视图
   4. ![avatar](http://static.jiebianjia.com/typora/04e92c0c44171b780309004d299b5683.png)

2. 前端配置

   1. api.js生成环境中 let base = ' '
   2. api.js开发环境中 let base = '/api'
   3. ![avatar](http://static.jiebianjia.com/typora/85cf1589ed7237bcbd68c7c203935ebc.png)

3. 项目部署

   ​	1.前端项目 build

   ​	2.后端项目新建static文件，将前端项目dist中的文件复制到static中

   ​	3.后端项目package

   ​	4.jar包部署
   
4. 数据库配置

   1. x_order_product_xx表新增驻地对应的订购产品
   2. bi_ui_deep表新增驻地对应的UI层级数据

### 大数据相关

#### Spark Job	项目名称BINebula/sparkJob

##### 主要内容

1. 按照基础数据的job以**Basedata**开头
2. 按小时计算的job以**Online**开头
3. 订购相关的job以**ProOrder**开头

#### Hdfs存储

1. HDFS存储服务器，观察目录 http://bigdatatopdraw001:9870/ 

2. 相关BI目录

3. ![avatar](img\image-20200330110122568.png)

4. 按照基础数据/异常数据/元数据区分目录

   ![avatar](http://static.jiebianjia.com/typora/6932b89ba440439d84f3e27f4ccf7836.png)

   

  5.基础数据依次为所有订购数据/所有用户/最近收藏/每日UI/每日用户去重/每日用户不去重/有效时长

![avatar](http://static.jiebianjia.com/typora/05787810239d8fed1f617d0b2c3f0504.png)

​	6.河北报表数据相关的job

​		![image-20200402091725565](C:\Users\Admin\AppData\Roaming\Typora\typora-user-images\image-20200402091725565.png)

```java
1.Hb_bb_auth				河北驻地所有包月数据
2.Hb_bb_auth_playTime   	河北驻地订购用户的有效播放
3.Hb_bb_otherCp    			河北驻地CP相关的播放数据以及订购数据
4.Hb_bb_otherCp_week_Top	河北驻地CP周播放数据Top10   
```

#### kafka 相关	项目名称BINebula/springkafkaetl

##### 主要内容

1. 目前kafkaConsumer部署在**47.100.131.226**服务器，jar包在**/app/springboot_jar**
2. 根据不同的驻地进行区分
3. ![avatar](http://static.jiebianjia.com/typora/d9f1c57e53c70beae0f41737ec410fae.png)
4. KafkaConsumer的主要逻辑

```java
1.拉取消息，首选进行过滤，再按照对应的目录进行上传到具体的hdfs目录，目录格式为    
    site/app/MetaDatas/day/hour/topic
2.配置conf    
    conf.set("fs.defaultFS", "hdfs://ns1");
	conf.setBoolean("dfs.support.append", true);
	conf.set("dfs.client.block.write.replace-datanode-on-failure.policy", "NEVER");
	conf.set("dfs.client.block.write.replace-datanode-on-failure.enable", "true");
```

​	5.河北Kafka的部署信息

```java
1.kafkaConsumer	jar包文件目录在/app/springboot_jar
```



##### 遇到的问题

1. 新增驻地，部署对应的KafkaConsumer

   1. 修改对应的kafkaListener()

   2. ![avatar](img\image-20200331093113471.png)

   3. 修改配置文件，避免在一个消费者组和占用同一个端口

      ![avatar](img\image-20200331093208669.png)

#### 河北鉴权同步	项目名称BINebula/synAuth

##### 主要内容

1. 从**x_auth_record_ctc_hebei**鉴权表找到当天最新的数据，遍历**x_hb_auth_record**的用户状态，对于已存在的进行更新，未存在的新增，bi系统中对于的表为**x_hb_auth_record**
2. 目前该项目部署在**10.0.0.36**服务器的**/app/tomcat03**
3. ![avatar](http://static.jiebianjia.com/typora/bbf1aa64eb2c730f02e6a08454d3dc40.png)

